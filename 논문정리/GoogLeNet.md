# GoogLeNet

GoogLeNet은 2014년 이미지넷 이미지 인식 대회(ILSVRC)에서 VGGNet(VGG19)을 이기고 우승을 차지한 알고리즘이다. GoogLeNet의 논문은 Christian Szegedy 등에 의해 2015 CVPR에 기재된 "Going Deeper with Convolutions"이다. GoogLeNet이란 이름에서 알 수 있듯이 Google이 알고리즘 개발에 참여했다.

## GoogLeNet의 구조

먼저 GoogLeNet의 구조도를 살펴보자.

<img width="724" alt="스크린샷 2020-12-17 오후 12 10 51" src="https://user-images.githubusercontent.com/69491771/102439089-ef413c00-4060-11eb-97ee-66cbd899c8f2.png"> 

GoogLeNet은 위 그림과 같이 22개 층으로 구성되어 있다. 파란색 블럭의 층수를 세보면 22개 층임을 알 수 있다. 이제 GoogLeNet의 특징들을 하나하나 살펴보자.

### 1) 1x1 컨볼루션

먼저 주목해야할 것은 1x1 사이즈의 필터로 컨볼루션 해주는 것이다. 구조도를 보면 곳곳에 1x1 컨볼루션 연산이 있음을 확인할 수 있다.

<img width="725" alt="스크린샷 2020-12-17 오후 12 14 54" src="https://user-images.githubusercontent.com/69491771/102439368-83130800-4061-11eb-9558-aeee6f325fdd.png"> 

1x1 컨볼루션은 어떤 의미를 갖는 것일까? 왜 해주는 것일까? GoogLeNet에서 1x1 컨볼루션은 특성맵의 갯수를 줄이는 목적으로 사용된다. 특성맵의 갯수가 줄어들면 그만큼 연산량이 줄어든다.

예를 들어,  480장의 14x14 사이즈의 특성맵(14x14x480)이 있다고 가정해보자. 이것을 48개의 5x5x480의 필터로 컨볼루션을 해주면 48장의 14x14의 특성맵(14x14x48)이 생성된다. 이때 필요한 연산 횟수는 얼마나 될까? (14x14x480) * (5x5x480) =약 112.9M이 된다.

이번에는 480장의 14x14 특성맵(14x14x480)을 먼저 16개의 1x1x480의 필터로 컨볼루션을 해줘 특성맵의 갯수를 줄여보자. 결과적으로 16장의 14x14의 특성맵(14x14x16)이 생성된다. 480장의 특성맵이 16장의 특성맵으로 줄어든 것에 주목하자. 이 14x14x16 특성맵을 48개의 5x5x16의 필터로 컨볼루션을 해주면 48장의 14x14의 특성맵(14x14x48)이 생성된다. 위에서 1x1 컨볼루션이 없을 때와 결과적으로 산출된 특성맵의 크기와 깊이는 같다는 것을 확인하자. 그럼 이때 필요한 연산횟수는 얼마일까? (14x14x16) * (1x1x480) + (14x14x48) * (5x5x16) = 약 5.3M이다. 112.9M에 비해 훨씬 더 적은 연산량을 가짐을 확인할 수 있다. 연산량을 줄일 수 있다는 점은 네트워크를 더 깊이 만들 수 있게 도와준다는 점이 중요하다.

<img width="626" alt="스크린샷 2020-12-17 오후 12 30 05" src="https://user-images.githubusercontent.com/69491771/102441023-ca4ec800-4064-11eb-89d2-25b785ac88f0.png"> 

### 2) Inception 모듈

이번엔 GoogLeNet의 핵심인 Inception 모듈에 대해 살펴보자. Inception 모듈들을 위 구조도에서 표시하면 다음과 같다.

<img width="735" alt="스크린샷 2020-12-17 오후 12 40 36" src="https://user-images.githubusercontent.com/69491771/102441337-67116580-4065-11eb-8834-cc111f7b274b.png"> 

GoogLeNet은 총 9개의 인셉션 모듈을 포함하고 있다. 인셉션 모듈을 하나 확대해서 자세히 살펴보자.

<img width="490" alt="스크린샷 2020-12-17 오후 12 45 00" src="https://user-images.githubusercontent.com/69491771/102441479-b35ca580-4065-11eb-88ac-c2744caf9722.png"> 

GoogLeNet에 실제로 사용된 모듈은 1x1 컨볼루션이 포함된 (b) 모델이다. 아까 살펴봤듯이 1x1 컨볼루션은 특성맵의 장수를 줄여주는 역할을 한다. 노란색 블럭으로 표현된 1x1 컨볼루션을 제외한 나이브(naive) 버전을 살펴보면, 이전 층에서 생성된 특성맵을 1x1 컨볼루션, 3x3 컨볼루션, 5x5 컨볼루션, 3x3 maxpooling 해준 결과 얻은 특성맵들을 모두 함께 쌓아준다. AlexNet, VGGNet 등의 이전 CNN 모델들은 한층에서 동일한 사이즈의 필터을 이용해서 컨볼루션을 해줬던 것과 차이가 있다. 따라서 좀 더 다양한 종류의 특성이 도출된다. 여기에 1x1 컨볼루션이 포함되었으니 당연히 연산량은 많이 줄어들었을 것이다.

### 3) Global average pooling

AlexNet, VGGNet 등에서는 Fully Connected(FC) 층들이 망의 후반부에 연결되어있다. 그러나 GoogLeNet은 FC방식 대신 Global average pooling은 전 층에서 산출된 특성맵들을 각각 평균낸 것을 이어서 1차원 벡터를 만들어주는 것이다. 1차원 벡터를 만들어줘야 최종적으로 이미지 분류를 위한 softmax 층을 연결해줄 수 있기 때문이다. 만약 전 층에서 1024장의 7x7의 특성맵이 생성된다면, 1024장의 7x7 특성맵 각각 평균을 내주어 얻은 1024개의 값을 하나의 벡터로 연결해주는 것이다.

<img width="689" alt="스크린샷 2020-12-17 오후 12 59 38" src="https://user-images.githubusercontent.com/69491771/102442436-bf496700-4067-11eb-8196-10baf0a801d0.png"> 

이렇게 해줌으로 얻을 수 있는 장점은 가중치의 갯수를 상당히 많이 없애준다는 것이다. 만약 FC방식을 사용한다면 훈련이 필요한 가중치의 갯수가 7x7x1024x1024 = 51.3M이지만 Global average pooling을 사용하면 가중치가 단 한개도 필요하지않다.

### 4) Auxiliary classifier

네트워크의 깊이가 깊어지면 깊어질수록 vanishing gradient 문제를 피하기 어려워진다. 그러니까 가중치를 훈련하는 과정에 역전차(Back propagation)를 주로 활용하는데 , 역전파 과정에서 가중치를 업데이트하는데 사용되는 greadient가 점점 작아져서 0이 되어버는 것이다. 따라서 네트워크 내의 가중치들이 제대로 훈련되지 않는다. 이 문제를 극복하기 위해서 GoogLeNet에서는 네트워크 중간에 두개의 보조 분류기(Auxiliary classifier)를 달아주었다.

<img width="739" alt="스크린샷 2020-12-17 오후 1 07 21" src="https://user-images.githubusercontent.com/69491771/102442914-db99d380-4068-11eb-9298-66c87cb3dc8d.png">   

이 보조 분류기들은 훈련시에만 활용되고 사용할 때는 제가해준다.

